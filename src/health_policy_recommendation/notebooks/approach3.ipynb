{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   age                1338 non-null   int64  \n",
      " 1   sex                1338 non-null   object \n",
      " 2   bmi                1338 non-null   float64\n",
      " 3   children           1338 non-null   int64  \n",
      " 4   smoker             1338 non-null   object \n",
      " 5   region             1338 non-null   object \n",
      " 6   charges            1338 non-null   float64\n",
      " 7   insurance_company  1338 non-null   object \n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 83.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"D:/WORKSPACE_CS/LJMU_Research/other/dash/health_policy_recommendation/src/health_policy_recommendation/data/ushealthinsurance_with_company3.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approach 1\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "\n",
    "region_budget_encoder = joblib.load(r'D:\\WORKSPACE_CS\\LJMU_Research\\other\\dash\\health_policy_recommendation\\src\\health_policy_recommendation\\models\\content_based\\region_budget_encoder.pkl')\n",
    "company_vectors = pd.read_csv(r'D:\\WORKSPACE_CS\\LJMU_Research\\other\\dash\\health_policy_recommendation\\src\\health_policy_recommendation\\models\\content_based\\company_vectors.csv', index_col=0)\n",
    "\n",
    "\n",
    "def feedback_score(row):\n",
    "    budget_score = {\"low\": 5, \"medium\": 3, \"high\": 1}.get(row[\"user_budget\"], 0)\n",
    "    smoker_score = {\"yes\": -1, \"no\": 1}.get(row[\"smoker\"], 0)\n",
    "    bmi_score = 1 if row[\"bmi\"] < 25 else -1\n",
    "\n",
    "    score = budget_score + smoker_score + bmi_score\n",
    "\n",
    "    # Clip the score between 0 and 5\n",
    "    return max(0, min(5, score))\n",
    "\n",
    "\n",
    "def health_score(row):\n",
    "    score = 2\n",
    "    if row[\"bmi\"] < 25:\n",
    "        score += 1\n",
    "    elif row[\"bmi\"] >= 30:\n",
    "        score -= 1\n",
    "\n",
    "    score += 1 if row[\"smoker\"] == \"no\" else -1\n",
    "    return score\n",
    "\n",
    "\n",
    "def create_user_vector(new_user_input: dict, encoder: OneHotEncoder) -> np.ndarray:\n",
    "    user_input_df = pd.DataFrame([new_user_input])\n",
    "    user_input_df[\"user_health_score\"] = user_input_df.apply(health_score, axis=1)\n",
    "\n",
    "    if \"user_feedback\" not in user_input_df.columns:\n",
    "        user_input_df[\"user_feedback\"] = user_input_df.apply(feedback_score, axis=1)\n",
    "\n",
    "    # Encode categorical features\n",
    "    encoded_cats = encoder.transform(user_input_df[[\"user_budget\", \"user_region\"]])\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaled_health = user_input_df[\"user_health_score\"] / 4.0\n",
    "    scaled_feedback = user_input_df[\"user_feedback\"] / 5.0\n",
    "\n",
    "    # Concatenate encoded and scaled features\n",
    "    user_vector = np.hstack(\n",
    "        (\n",
    "            encoded_cats,\n",
    "            scaled_health.values.reshape(-1, 1),\n",
    "            scaled_feedback.values.reshape(-1, 1),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return user_vector\n",
    "\n",
    "\n",
    "def recomend(new_user_input, company_vectors, label_encoder):\n",
    "    # create user vector\n",
    "    user_vector = create_user_vector(new_user_input, label_encoder)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity(user_vector, company_vectors.values)\n",
    "\n",
    "    # Map scores back to company names for readability\n",
    "    similarity_scores = pd.Series(similarities[0], index=company_vectors.index)\n",
    "\n",
    "    # # Get the top recommendation\n",
    "    # recommendation = similarity_scores.idxmax() # Get the index (company name) of the max score\n",
    "    # highest_score = similarity_scores.max()\n",
    "\n",
    "    # return recommendation, highest_score\n",
    "\n",
    "    # Display ranked top 3 recommendations\n",
    "    recommendation = similarity_scores.sort_values(ascending=False).iloc[:3]\n",
    "    return recommendation.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\n",
    "    r\"D:\\WORKSPACE_CS\\LJMU_Research\\other\\dash\\health_policy_recommendation\\src\\health_policy_recommendation\\models\\insurance_model.pkl\"\n",
    ")\n",
    "\n",
    "model_features = joblib.load(\n",
    "    r\"D:\\WORKSPACE_CS\\LJMU_Research\\other\\dash\\health_policy_recommendation\\src\\health_policy_recommendation\\models\\model_features.pkl\"\n",
    ")\n",
    "\n",
    "label_enconder = joblib.load(\n",
    "    r\"D:\\WORKSPACE_CS\\LJMU_Research\\other\\dash\\health_policy_recommendation\\src\\health_policy_recommendation\\models\\label_encoder.pkl\"\n",
    ")\n",
    "\n",
    "\n",
    "# Basic (Static Preferences)\n",
    "\n",
    "\n",
    "def get_utility_scores_for_user(user_input_df):\n",
    "    # Example static mapping (normally you'd fetch this from user profile/preferences)\n",
    "\n",
    "    preferred_region = (\n",
    "        user_input_df.iloc[0][\"preferred_region\"] or user_input_df.iloc[0][\"region\"]\n",
    "    )\n",
    "\n",
    "    budget_level = user_input_df.iloc[0][\"budget\"]  # low / medium / high\n",
    "\n",
    "    # Define utility rules for companies (this could come from a config or DB)\n",
    "    company_meta = {\n",
    "        \"Company A\": {\"region\": \"northwest\", \"price\": \"medium\"},\n",
    "        \"Company B\": {\"region\": \"southeast\", \"price\": \"low\"},\n",
    "        \"Company C\": {\"region\": \"southwest\", \"price\": \"high\"},\n",
    "        \"Company D\": {\"region\": \"northeast\", \"price\": \"medium\"},\n",
    "    }\n",
    "\n",
    "    utility_scores = {}\n",
    "\n",
    "    for company, meta in company_meta.items():\n",
    "        score = 1.0  # base utility\n",
    "\n",
    "        # Increase utility if region matches\n",
    "        if meta[\"region\"] == preferred_region:\n",
    "            score += 0.3\n",
    "\n",
    "        # Modify based on budget match\n",
    "        if meta[\"price\"] == budget_level:\n",
    "            score += 0.2\n",
    "\n",
    "        utility_scores[company] = score\n",
    "\n",
    "    return utility_scores\n",
    "\n",
    "\n",
    "def preprocess_user_input(user_input_df, model_features):\n",
    "    # One-hot encode like training\n",
    "    user_input_encoded = pd.get_dummies(\n",
    "        user_input_df, columns=[\"sex\", \"smoker\", \"region\", \"budget\"], drop_first=True\n",
    "    )\n",
    "\n",
    "    # Add missing columns that existed during training\n",
    "    for col in model_features:\n",
    "        if col not in user_input_encoded.columns:\n",
    "            user_input_encoded[col] = 0\n",
    "\n",
    "    # Reorder to match model input exactly\n",
    "    user_input_encoded = user_input_encoded[model_features]\n",
    "\n",
    "    return user_input_encoded\n",
    "\n",
    "\n",
    "def health_score(row):\n",
    "    score = 2\n",
    "    if row[\"bmi\"] < 25:\n",
    "        score += 1\n",
    "    elif row[\"bmi\"] >= 30:\n",
    "        score -= 1\n",
    "\n",
    "    score += 1 if row[\"smoker\"] == \"no\" else -1\n",
    "    return score\n",
    "\n",
    "\n",
    "def predict(user_input_df, top_n=3):\n",
    "\n",
    "    user_input_df = pd.DataFrame([user_input_df])\n",
    "\n",
    "    # Map budget to score\n",
    "    budget_score = user_input_df[\"budget\"].map({\"low\": 5, \"medium\": 3, \"high\": 1})\n",
    "\n",
    "    # Compute feedback\n",
    "    user_input_df[\"feedback\"] = (\n",
    "        budget_score\n",
    "        + user_input_df[\"smoker\"].map({\"yes\": -1, \"no\": 1})\n",
    "        + user_input_df[\"bmi\"].apply(lambda x: 1 if x < 25 else -1)\n",
    "    )\n",
    "\n",
    "    # Clip to range 0â€“5\n",
    "    user_input_df[\"feedback\"] = user_input_df[\"feedback\"].clip(0, 5)\n",
    "\n",
    "    user_input_df[\"health_score\"] = user_input_df.apply(health_score, axis=1)\n",
    "\n",
    "    # Preprocess user input to match training features\n",
    "    user_input_encoded = preprocess_user_input(user_input_df, model_features)\n",
    "\n",
    "    # Step 1: Predict class probabilities\n",
    "    probs = model.predict_proba(user_input_encoded)\n",
    "    class_names = label_enconder.inverse_transform(\n",
    "        model.classes_\n",
    "    )  # get original labels\n",
    "\n",
    "    # Step 2: Get top-N most probable recommendations\n",
    "    # top_n_probs = sorted(\n",
    "    #     list(zip(class_names, probs[0])),\n",
    "    #     key=lambda x: x[1],\n",
    "    #     reverse=True\n",
    "    # )[:top_n]\n",
    "\n",
    "    prob_dict = dict(zip(class_names, probs[0]))  # {'CompanyA': 0.45, ...}\n",
    "\n",
    "    # Step 3: Sort and get top-N as a dictionary\n",
    "    top_n_probs = dict(\n",
    "        sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    )\n",
    "\n",
    "    # # Step 3: Fetch user-specific utility scores\n",
    "    # utility_scores = get_utility_scores_for_user(user_input_df)\n",
    "\n",
    "    # # Step 4: Multiply probabilities with utility scores\n",
    "    # recommendations = {\n",
    "    #     company: prob * utility_scores.get(company, 1.0)  # Default utility = 1.0 if not found\n",
    "    #     for company, prob in top_n_probs.items()\n",
    "    # }\n",
    "\n",
    "    # Step 5: Re-rank based on adjusted utility score\n",
    "    # recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # return recommendations\n",
    "\n",
    "    return top_n_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_recommendations(similarity_scores, feedback_scores, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Combine content-based similarity scores with utility-based ML predictions.\n",
    "\n",
    "    Parameters:\n",
    "        similarity_scores (dict): item_id -> content-based similarity score.\n",
    "        feedback_scores (dict): item_id -> utility/feedback score from ML model.\n",
    "        alpha (float): Balance between content-based and ML-based scores.\n",
    "                       alpha=1: only content-based; alpha=0: only ML-based.\n",
    "\n",
    "    Returns:\n",
    "        fused_scores (dict): item_id -> combined fused score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Align the items present in both systems\n",
    "    item_ids = list(set(similarity_scores) | set(feedback_scores))\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"item_id\": item_ids,\n",
    "            \"similarity_score\": [similarity_scores.get(i, 0) for i in item_ids],\n",
    "            \"feedback_score\": [feedback_scores.get(i, 0) for i in item_ids],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Fuse scores using weighted average\n",
    "    df[\"fused_score\"] = (\n",
    "        alpha * df[\"similarity_score\"] + (1 - alpha) * df[\"feedback_score\"]\n",
    "    )\n",
    "\n",
    "    # Sort or filter if needed:\n",
    "    df = df.sort_values(by=\"fused_score\", ascending=False)[:3]\n",
    "\n",
    "    return dict(zip(df[\"item_id\"], df[\"fused_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_input = {\n",
    "    'age': 19,\n",
    "    'sex': 'female',\n",
    "    'bmi': 27.9,\n",
    "    'children': 0,\n",
    "    'smoker': 'yes',\n",
    "    'region': 'southeast',\n",
    "    'budget': 'high',\n",
    "    'user_feedback': 4.0,\n",
    "}\n",
    "\n",
    "# Derive and restructure into UserPreferences3 format\n",
    "user_preferences_payload = {\n",
    "    \"user_preferences_1\": {\n",
    "        \"user_budget\": new_user_input[\"budget\"],\n",
    "        \"user_region\": new_user_input[\"region\"],\n",
    "        \"bmi\": new_user_input[\"bmi\"],\n",
    "        \"smoker\": new_user_input[\"smoker\"],\n",
    "        \"user_feedback\": new_user_input.get(\"user_feedback\"),\n",
    "    },\n",
    "    \"user_preferences_2\": {\n",
    "        \"age\": new_user_input[\"age\"],\n",
    "        \"sex\": new_user_input[\"sex\"],\n",
    "        \"bmi\": new_user_input[\"bmi\"],\n",
    "        \"children\": new_user_input[\"children\"],\n",
    "        \"smoker\": new_user_input[\"smoker\"],\n",
    "        \"region\": new_user_input[\"region\"],\n",
    "        \"budget\": new_user_input[\"budget\"],\n",
    "        \"preferred_region\": new_user_input.get(\"region\"),\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recommendation(user_preferences_1: dict):\n",
    "    return recomend(user_preferences_1, company_vectors, region_budget_encoder)\n",
    "\n",
    "def model_based_recommendation(user_preferences_2: dict):\n",
    "    return predict(user_preferences_2, top_n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_result = content_based_recommendation(user_preferences_payload['user_preferences_1'])\n",
    "model_based_result = model_based_recommendation(user_preferences_payload['user_preferences_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_recomendation = fuse_recommendations(content_based_result, model_based_result, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Company C': 0.9388967556074301,\n",
       " 'Company B': 0.5244893467738976,\n",
       " 'Company D': 0.3794639181751614}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_recomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "\n",
    "def precision_at_k(recommended_items, relevant_items, k):\n",
    "    recommended_k = recommended_items[:k]\n",
    "    return len(set(recommended_k) & set(relevant_items)) / k\n",
    "\n",
    "def recall_at_k(recommended_items, relevant_items, k):\n",
    "    recommended_k = recommended_items[:k]\n",
    "    return len(set(recommended_k) & set(relevant_items)) / len(relevant_items) if relevant_items else 0\n",
    "\n",
    "def hit_at_k(recommended_items, relevant_items, k):\n",
    "    recommended_k = recommended_items[:k]\n",
    "    return 1 if set(recommended_k) & set(relevant_items) else 0\n",
    "\n",
    "def ndcg_at_k(recommended_items, relevant_items, k):\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended_items[:k]):\n",
    "        if item in relevant_items:\n",
    "            dcg += 1 / np.log2(i + 2)\n",
    "    idcg = sum([1 / np.log2(i + 2) for i in range(min(len(relevant_items), k))])\n",
    "    return dcg / idcg if idcg > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_content_based(similarity_scores, ground_truth, k=5):\n",
    "    recommended_items = [item for item, _ in sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)]\n",
    "    return {\n",
    "        'Precision@K': precision_at_k(recommended_items, ground_truth, k),\n",
    "        'Recall@K': recall_at_k(recommended_items, ground_truth, k),\n",
    "        'Hit@K': hit_at_k(recommended_items, ground_truth, k),\n",
    "        'NDCG@K': ndcg_at_k(recommended_items, ground_truth, k)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = evaluate_content_based(combined_recomendation, )   # incomplete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
